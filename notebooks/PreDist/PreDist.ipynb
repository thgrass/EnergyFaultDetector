{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# EnergyFaultDetector @ District Heatin\n",
    "\n",
    "This notebook shows how to apply the EnergyFaultDetector on the PreDist dataset (available on [zenodo](https://doi.org/10.5281/zenodo.17522254)) and how to reproduce results from the accompanying paper (preprint available on [arXiv](https://doi.org/10.48550/arXiv.2511.14791))."
   ],
   "id": "b3569887686796a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T12:10:00.352157Z",
     "start_time": "2026-01-08T12:09:52.718327900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "\n",
    "from energy_fault_detector.evaluation import PreDistDataset\n",
    "from energy_fault_detector import FaultDetector, Config\n",
    "from energy_fault_detector.utils.visualisation import plot_score_with_threshold, plot_reconstruction\n",
    "from energy_fault_detector.utils.analysis import create_events\n",
    "\n",
    "from predist_utils import train_or_get_model, find_optimal_threshold, get_arcana_importances"
   ],
   "id": "a149ecfec1850ff7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\croelofs\\PycharmProjects\\EnergyFaultDetector\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load dataset",
   "id": "5cab669e1b0c15d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T12:10:00.401341700Z",
     "start_time": "2026-01-08T12:10:00.352934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = PreDistDataset('./predist_data', download_dataset=False)\n",
    "# Check events for manufacturer 1\n",
    "dataset.events[1]"
   ],
   "id": "b3f587b734b87ccc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          substation ID         Report date       Problem EN  \\\n",
       "Event ID                                                       \n",
       "1                    10 2014-05-04 14:44:00           no DHW   \n",
       "3                    12 2015-12-01 10:56:00          no heat   \n",
       "5                    11 2018-11-23 08:30:00          no heat   \n",
       "6                    21 2016-12-06 13:12:00  not enough heat   \n",
       "7                    26 2020-06-13 10:38:00           no DHW   \n",
       "...                 ...                 ...              ...   \n",
       "58                    5                 NaT              NaN   \n",
       "59                   22                 NaT              NaN   \n",
       "61                   14                 NaT              NaN   \n",
       "66                   19                 NaT              NaN   \n",
       "68                   13                 NaT              NaN   \n",
       "\n",
       "                                       Event description EN  \\\n",
       "Event ID                                                      \n",
       "1             No hot water. Actuator (DHW system) replaced.   \n",
       "3                               Control parameters updated.   \n",
       "5                                    Pump settings updated.   \n",
       "6         The heaters are not getting warm enough. Suppl...   \n",
       "7                  The needle valve was closed. Readjusted.   \n",
       "...                                                     ...   \n",
       "58                                                      NaN   \n",
       "59                                                      NaN   \n",
       "61                                                      NaN   \n",
       "66                                                      NaN   \n",
       "68                                                      NaN   \n",
       "\n",
       "         Possible anomaly start Possible anomaly end      Training start  \\\n",
       "Event ID                                                                   \n",
       "1           2014-05-03 16:00:00  2014-05-05 04:00:00 2012-03-28 09:00:00   \n",
       "3           2015-11-29 12:00:00  2015-12-02 10:56:00 2015-03-01 00:00:00   \n",
       "5                           NaT  2018-11-26 09:56:59 2015-02-20 14:00:00   \n",
       "6                           NaT  2016-12-07 13:12:00 2015-11-30 09:00:00   \n",
       "7           2020-06-12 12:00:00  2020-06-14 10:38:00 2018-10-18 13:00:00   \n",
       "...                         ...                  ...                 ...   \n",
       "58                          NaT                  NaT 2016-02-29 00:00:00   \n",
       "59                          NaT                  NaT 2018-06-21 10:00:00   \n",
       "61                          NaT                  NaT 2017-12-04 00:00:00   \n",
       "66                          NaT                  NaT 2015-09-15 09:31:00   \n",
       "68                          NaT                  NaT 2017-12-19 00:00:00   \n",
       "\n",
       "                Training end efd_possible  \\\n",
       "Event ID                                    \n",
       "1        2014-04-20 14:44:00         True   \n",
       "3        2015-11-17 10:56:00         True   \n",
       "5        2018-11-09 08:30:00         True   \n",
       "6        2016-11-22 13:12:00         True   \n",
       "7        2020-05-30 10:38:00         True   \n",
       "...                      ...          ...   \n",
       "58       2018-02-28 00:00:00          NaN   \n",
       "59       2019-01-31 00:00:00          NaN   \n",
       "61       2019-12-05 00:00:00          NaN   \n",
       "66       2017-06-14 00:00:00          NaN   \n",
       "68       2019-12-20 00:00:00          NaN   \n",
       "\n",
       "                                                Fault label  \\\n",
       "Event ID                                                      \n",
       "1         Motorised control valve (primary side): Actuat...   \n",
       "3                  Control unit: Incorrect parameterisation   \n",
       "5                       Failure of the heating circuit pump   \n",
       "6                  Control unit: Incorrect parameterisation   \n",
       "7         Incorrect setting of the differential pressure...   \n",
       "...                                                     ...   \n",
       "58                                                      NaN   \n",
       "59                                                      NaN   \n",
       "61                                                      NaN   \n",
       "66                                                      NaN   \n",
       "68                                                      NaN   \n",
       "\n",
       "         Monitoring potential Event type           Event end Event start  \n",
       "Event ID                                                                  \n",
       "1                         3.4    anomaly 2014-05-04 14:44:00         NaT  \n",
       "3                           4    anomaly 2015-12-01 10:56:00         NaT  \n",
       "5                         3.8    anomaly 2018-11-23 08:30:00         NaT  \n",
       "6                           4    anomaly 2016-12-06 13:12:00         NaT  \n",
       "7                         3.1    anomaly 2020-06-13 10:38:00         NaT  \n",
       "...                       ...        ...                 ...         ...  \n",
       "58                        NaN     normal 2018-03-07 00:00:00  2018-02-28  \n",
       "59                        NaN     normal 2019-02-07 00:00:00  2019-01-31  \n",
       "61                        NaN     normal 2019-12-12 00:00:00  2019-12-05  \n",
       "66                        NaN     normal 2017-06-21 00:00:00  2017-06-14  \n",
       "68                        NaN     normal 2019-12-27 00:00:00  2019-12-20  \n",
       "\n",
       "[64 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>substation ID</th>\n",
       "      <th>Report date</th>\n",
       "      <th>Problem EN</th>\n",
       "      <th>Event description EN</th>\n",
       "      <th>Possible anomaly start</th>\n",
       "      <th>Possible anomaly end</th>\n",
       "      <th>Training start</th>\n",
       "      <th>Training end</th>\n",
       "      <th>efd_possible</th>\n",
       "      <th>Fault label</th>\n",
       "      <th>Monitoring potential</th>\n",
       "      <th>Event type</th>\n",
       "      <th>Event end</th>\n",
       "      <th>Event start</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Event ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2014-05-04 14:44:00</td>\n",
       "      <td>no DHW</td>\n",
       "      <td>No hot water. Actuator (DHW system) replaced.</td>\n",
       "      <td>2014-05-03 16:00:00</td>\n",
       "      <td>2014-05-05 04:00:00</td>\n",
       "      <td>2012-03-28 09:00:00</td>\n",
       "      <td>2014-04-20 14:44:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Motorised control valve (primary side): Actuat...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>2014-05-04 14:44:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2015-12-01 10:56:00</td>\n",
       "      <td>no heat</td>\n",
       "      <td>Control parameters updated.</td>\n",
       "      <td>2015-11-29 12:00:00</td>\n",
       "      <td>2015-12-02 10:56:00</td>\n",
       "      <td>2015-03-01 00:00:00</td>\n",
       "      <td>2015-11-17 10:56:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Control unit: Incorrect parameterisation</td>\n",
       "      <td>4</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>2015-12-01 10:56:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-23 08:30:00</td>\n",
       "      <td>no heat</td>\n",
       "      <td>Pump settings updated.</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-11-26 09:56:59</td>\n",
       "      <td>2015-02-20 14:00:00</td>\n",
       "      <td>2018-11-09 08:30:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Failure of the heating circuit pump</td>\n",
       "      <td>3.8</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>2018-11-23 08:30:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>2016-12-06 13:12:00</td>\n",
       "      <td>not enough heat</td>\n",
       "      <td>The heaters are not getting warm enough. Suppl...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-12-07 13:12:00</td>\n",
       "      <td>2015-11-30 09:00:00</td>\n",
       "      <td>2016-11-22 13:12:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Control unit: Incorrect parameterisation</td>\n",
       "      <td>4</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>2016-12-06 13:12:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>2020-06-13 10:38:00</td>\n",
       "      <td>no DHW</td>\n",
       "      <td>The needle valve was closed. Readjusted.</td>\n",
       "      <td>2020-06-12 12:00:00</td>\n",
       "      <td>2020-06-14 10:38:00</td>\n",
       "      <td>2018-10-18 13:00:00</td>\n",
       "      <td>2020-05-30 10:38:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Incorrect setting of the differential pressure...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>2020-06-13 10:38:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2016-02-29 00:00:00</td>\n",
       "      <td>2018-02-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2018-03-07 00:00:00</td>\n",
       "      <td>2018-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-06-21 10:00:00</td>\n",
       "      <td>2019-01-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2019-02-07 00:00:00</td>\n",
       "      <td>2019-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-12-04 00:00:00</td>\n",
       "      <td>2019-12-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2019-12-12 00:00:00</td>\n",
       "      <td>2019-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2015-09-15 09:31:00</td>\n",
       "      <td>2017-06-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2017-06-21 00:00:00</td>\n",
       "      <td>2017-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-12-19 00:00:00</td>\n",
       "      <td>2019-12-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>2019-12-27 00:00:00</td>\n",
       "      <td>2019-12-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create or load models (uses optimized configs)",
   "id": "ad56a689d11f8d2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T12:10:00.530885300Z",
     "start_time": "2026-01-08T12:10:00.438434900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_configs = {\n",
    "    1: {\n",
    "        'config_files': {\n",
    "            'default_ae': './configs/m1_default_ae.yaml',\n",
    "            'cond_ae': './configs/m1_cond_ae.yaml',\n",
    "            'doy_ae': './configs/m1_doy_ae.yaml'\n",
    "        },\n",
    "        'bottleneck': 0.65\n",
    "    },\n",
    "    2: {\n",
    "        'config_files': {\n",
    "            'default_ae': './configs/m2_default_ae.yaml',\n",
    "            'cond_ae': './configs/m2_cond_ae.yaml',\n",
    "            'doy_ae': './configs/m2_doy_ae.yaml'\n",
    "        },\n",
    "        'bottleneck': 0.25\n",
    "    }\n",
    "}\n",
    "\n",
    "# Model file exists, load the model\n",
    "load_from_file = True"
   ],
   "id": "c9177963f751115b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-08T12:10:00.633173600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create or load model, predict and collect results for all events\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# To test:\n",
    "manufacturers = [1, 2]  # [1, 2]\n",
    "models = ['default_ae', 'cond_ae']  # ['default_ae', 'cond_ae', 'doy_ae']\n",
    "\n",
    "results = {}\n",
    "for manufacturer in manufacturers:\n",
    "    results[manufacturer] = {}\n",
    "    for config_name, config_file in model_configs[manufacturer]['config_files'].items():\n",
    "        if config_name not in models:\n",
    "            continue\n",
    "\n",
    "        conf = Config(config_file)\n",
    "        dp_params = conf.config_dict['train']['data_preprocessor']['params']\n",
    "        ts_features = None\n",
    "        if dp_params.get('ts_features'):\n",
    "            ts_features = dp_params.pop('ts_features')  # remove time features from config\n",
    "\n",
    "        # Prepare parameters for parallel execution\n",
    "        bottleneck_ratio = model_configs[manufacturer]['bottleneck']\n",
    "        events_to_process = dataset.events[manufacturer].iterrows()\n",
    "\n",
    "        # Run parallel over events\n",
    "        # n_jobs=-1 uses all CPU cores. Adjust if memory is an issue.\n",
    "        parallel_results = Parallel(n_jobs=-1, verbose=10)(\n",
    "            delayed(train_or_get_model)(\n",
    "                event_id, dataset, manufacturer, config_name,\n",
    "                conf, bottleneck_ratio, load_from_file, ts_features\n",
    "            ) for event_id, event_row in events_to_process\n",
    "        )\n",
    "\n",
    "        # Create the results dictionary\n",
    "        results[manufacturer][config_name] = dict(parallel_results)"
   ],
   "id": "d6f9edc9349242ca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  64 | elapsed:  4.7min remaining:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  64 | elapsed:  5.2min remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  64 | elapsed:  7.7min remaining:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  64 | elapsed:  8.0min remaining:  1.7min\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Find optimal criticality threshold based on the reliability score\n",
    "Calculate max criticality before report date and optimize criticality threshold using 5-fold CV"
   ],
   "id": "3c0ee0eeabed5068"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_criticality_results = {}\n",
    "criticality_thresholds = {}\n",
    "predicted_anomalies = {}\n",
    "true_anomalies = {}\n",
    "\n",
    "for manufacturer in results.keys():\n",
    "    max_criticality_results[manufacturer] = {}\n",
    "    criticality_thresholds[manufacturer] = {}\n",
    "    predicted_anomalies[manufacturer] = {}\n",
    "\n",
    "    true_anomalies[manufacturer] = (dataset.events[manufacturer]['Event type'] == 'anomaly').astype(int)\n",
    "\n",
    "    for config_name, results_dict in results[manufacturer].items():\n",
    "\n",
    "        max_criticality_list = []\n",
    "        for event_id, prediction in results_dict.items():\n",
    "            event_row = dataset.events[manufacturer].loc[event_id]\n",
    "            max_criticality = prediction.criticality().loc[:event_row['Report date']].max()\n",
    "            max_criticality_list += [(event_id, max_criticality)]\n",
    "\n",
    "        c = pd.DataFrame(max_criticality_list, columns=['event_id', 'max_criticality'])\n",
    "        c = c.set_index('event_id')['max_criticality']\n",
    "        max_criticality_results[manufacturer][config_name] = c\n",
    "\n",
    "        criticality_threshold = find_optimal_threshold(\n",
    "            true_anomalies=true_anomalies[manufacturer],\n",
    "            max_criticalities=max_criticality_results[manufacturer][config_name],\n",
    "        )\n",
    "        criticality_thresholds[manufacturer][config_name] = criticality_threshold\n",
    "        predicted_anomalies[manufacturer][config_name] = c > criticality_threshold"
   ],
   "id": "4f741a688f149cd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Final results (reliability and eventwise precision+recall)",
   "id": "ae299a2f61b2f5a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for manufacturer in results.keys():\n",
    "    print(f'Manufacturer m{manufacturer}')\n",
    "    for config_name in results[manufacturer].keys():\n",
    "        print(f'Model {config_name}:')\n",
    "\n",
    "        reliability = fbeta_score(\n",
    "            true_anomalies[manufacturer], predicted_anomalies[manufacturer][config_name],\n",
    "            beta=0.5\n",
    "        )\n",
    "        precision = precision_score(\n",
    "            true_anomalies[manufacturer], predicted_anomalies[manufacturer][config_name]\n",
    "        )\n",
    "        recall = recall_score(\n",
    "            true_anomalies[manufacturer], predicted_anomalies[manufacturer][config_name]\n",
    "        )\n",
    "        print(f'Reliability: {reliability:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}')\n",
    "\n",
    "        disp = ConfusionMatrixDisplay.from_predictions(\n",
    "            y_true=true_anomalies[manufacturer], y_pred=predicted_anomalies[manufacturer][config_name],\n",
    "            cmap='Blues',\n",
    "            labels=[False, True],\n",
    "            display_labels=['Normal', 'Anomaly'],\n",
    "        )\n"
   ],
   "id": "3b5c248383e4592e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualise results",
   "id": "570ebfedc795dd61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "manufacturer = 1\n",
    "config_name = 'cond_ae'\n",
    "event_id = 49\n",
    "report_date = dataset.events[manufacturer].loc[event_id]['Report date']\n",
    "\n",
    "# Event details\n",
    "dataset.events[manufacturer].loc[event_id]"
   ],
   "id": "a761ecfa7874e175",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Criticality",
   "id": "e1d0ace838ed0d5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = results[manufacturer][config_name][event_id]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,3))\n",
    "crit = predictions.criticality()\n",
    "crit.plot(ax=ax, label=config_name)\n",
    "\n",
    "ax.axvline(report_date, label='incident report', c='r', linestyle='-')\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_ylabel('criticality')\n",
    "ax.set_xlabel('')"
   ],
   "id": "5236c23c789fdd72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ARCANA results",
   "id": "814da89e48b3860c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_data = dataset.get_event_data(manufacturer, event_id)['test_data']\n",
    "\n",
    "# find longest detected anomaly event (continuous run of predicted anomalous timestamps)\n",
    "anomaly_events, _ = create_events(\n",
    "    test_data,\n",
    "    predictions.predicted_anomalies,\n",
    "    min_event_length=12\n",
    ")\n",
    "longest_anomaly_event = anomaly_events[anomaly_events['duration'] == anomaly_events['duration'].max()].iloc[0]\n",
    "\n",
    "# Calculate ARCANA feature importances\n",
    "top_features = get_arcana_importances(manufacturer, event_id, config_name, test_data.loc[longest_anomaly_event['start']:report_date])\n",
    "\n",
    "top_features"
   ],
   "id": "b8a234e31eeecc66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the reconstruction of the top 3\n",
    "fig, ax = plot_reconstruction(test_data, predictions.reconstruction, top_features.index[:3].to_list())\n",
    "\n",
    "for ax_ in ax:\n",
    "    ax_.axvline(report_date, label='incident report', color='r', linestyle='-')\n",
    "\n",
    "ax[0].legend(loc='upper left')"
   ],
   "id": "d0cbfbada56ec052",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ef36d5c93501b213",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
